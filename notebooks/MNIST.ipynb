{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'./../../../alan/CSGAN/')\n",
    "\n",
    "import csgan as cs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../dataset/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ../../../dataset/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../../dataset/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../../dataset/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../../../dataset/mnist/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mnist.train.images[:55000,:]\n",
    "x_train.shape\n",
    "\n",
    "class data_provider(object):\n",
    "    def __init__(self,x_train):\n",
    "        self.x_train = x_train\n",
    "        self.num = x_train.shape[0]\n",
    "        \n",
    "    def __call__(self,n):\n",
    "        n_list = np.arange(self.num)\n",
    "        random.shuffle(n_list)\n",
    "        return self.x_train[n_list[:n]].reshape(n,28,28,1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHwiK8ANBEX4gKMIPBEX4gaAIPxDU/wMPv/j5k3jnGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbac8ed7fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dp = data_provider(x_train)\n",
    "    \n",
    "image = dp(10)[0].reshape([28,28])\n",
    "plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp(10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size is same as input's!\n",
      " [*] Reading checkpoints...\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/28_28/DCGAN.model-2002\n",
      " [*] Success to read DCGAN.model-2002\n",
      " [*] Load SUCCESS\n",
      "Epoch: [ 0] [  98/ 200] time: 146.5149, d_loss: 0.28772438, g_loss: 2.44617558\n",
      "Epoch: [ 0] [ 198/ 200] time: 279.3275, d_loss: 0.11351220, g_loss: 2.94747210\n",
      "./samples/train_00_0198.png\n",
      "Epoch: [ 1] [  98/ 200] time: 397.5464, d_loss: 0.15292561, g_loss: 2.45058489\n",
      "Epoch: [ 1] [ 198/ 200] time: 514.8439, d_loss: 0.12522458, g_loss: 2.60880780\n",
      "./samples/train_01_0198.png\n"
     ]
    }
   ],
   "source": [
    "dcgan = cs.DCGAN(\n",
    "    data_provider = dp,\n",
    "    batch_size=17,\n",
    "    gf_dim=16, df_dim=64,\n",
    "    z_dim=100,\n",
    "    checkpoint_dir='./checkpoint/',save_per = 100)\n",
    "\n",
    "dcgan.train(num_epoch=2,batch_per_epoch = 200,verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input1 = tf.random_normal([1,10,10,32])\n",
    "input2 = tf.random_normal([1,20,20,32])\n",
    "\n",
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    # Create variable named \"weights\".\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
    "        initializer=tf.random_normal_initializer())\n",
    "    # Create variable named \"biases\".\n",
    "    biases = tf.get_variable(\"biases\", bias_shape,\n",
    "        initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)\n",
    "\n",
    "\n",
    "def my_image_filter(input_images):\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n",
    "        return conv_relu(relu1, [5, 5, 32, 32], [32])\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"model\"):\n",
    "    output1 = my_image_filter(input1)\n",
    "with tf.variable_scope(\"model\", reuse=True):\n",
    "    output2 = my_image_filter(input2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'random_normal/shape',\n",
       " u'random_normal/mean',\n",
       " u'random_normal/stddev',\n",
       " u'random_normal/RandomStandardNormal',\n",
       " u'random_normal/mul',\n",
       " u'random_normal',\n",
       " u'random_normal_1/shape',\n",
       " u'random_normal_1/mean',\n",
       " u'random_normal_1/stddev',\n",
       " u'random_normal_1/RandomStandardNormal',\n",
       " u'random_normal_1/mul',\n",
       " u'random_normal_1',\n",
       " u'model/conv1/weights/Initializer/random_normal/shape',\n",
       " u'model/conv1/weights/Initializer/random_normal/mean',\n",
       " u'model/conv1/weights/Initializer/random_normal/stddev',\n",
       " u'model/conv1/weights/Initializer/random_normal/RandomStandardNormal',\n",
       " u'model/conv1/weights/Initializer/random_normal/mul',\n",
       " u'model/conv1/weights/Initializer/random_normal',\n",
       " u'model/conv1/weights',\n",
       " u'model/conv1/weights/Assign',\n",
       " u'model/conv1/weights/read',\n",
       " u'model/conv1/biases/Initializer/Const',\n",
       " u'model/conv1/biases',\n",
       " u'model/conv1/biases/Assign',\n",
       " u'model/conv1/biases/read',\n",
       " u'model/conv1/Conv2D',\n",
       " u'model/conv1/add',\n",
       " u'model/conv1/Relu',\n",
       " u'model/conv2/weights/Initializer/random_normal/shape',\n",
       " u'model/conv2/weights/Initializer/random_normal/mean',\n",
       " u'model/conv2/weights/Initializer/random_normal/stddev',\n",
       " u'model/conv2/weights/Initializer/random_normal/RandomStandardNormal',\n",
       " u'model/conv2/weights/Initializer/random_normal/mul',\n",
       " u'model/conv2/weights/Initializer/random_normal',\n",
       " u'model/conv2/weights',\n",
       " u'model/conv2/weights/Assign',\n",
       " u'model/conv2/weights/read',\n",
       " u'model/conv2/biases/Initializer/Const',\n",
       " u'model/conv2/biases',\n",
       " u'model/conv2/biases/Assign',\n",
       " u'model/conv2/biases/read',\n",
       " u'model/conv2/Conv2D',\n",
       " u'model/conv2/add',\n",
       " u'model/conv2/Relu',\n",
       " u'model_1/conv1/Conv2D',\n",
       " u'model_1/conv1/add',\n",
       " u'model_1/conv1/Relu',\n",
       " u'model_1/conv2/Conv2D',\n",
       " u'model_1/conv2/add',\n",
       " u'model_1/conv2/Relu']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "from skimage.draw import circle,polygon,circle_perimeter,polygon_perimeter\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xc = 30\n",
    "yc = 60\n",
    "radius = 20\n",
    "\n",
    "img = np.zeros((100, 100), dtype=np.uint8)\n",
    "rr, cc = circle(c=xc, r=yc, radius=radius)\n",
    "img[rr, cc] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = np.array([yc-radius, yc, yc+radius])\n",
    "c = np.array([xc-radius, xc, xc-radius])\n",
    "rr, cc = polygon(r, c)\n",
    "img[rr, cc] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fef86888910>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fef86969310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dense in module tensorflow.python.layers.core:\n",
      "\n",
      "dense(inputs, units, activation=None, use_bias=True, kernel_initializer=None, bias_initializer=<tensorflow.python.ops.init_ops.Zeros object>, kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, trainable=True, name=None, reuse=None)\n",
      "    Functional interface for the densely-connected layer.\n",
      "    \n",
      "    This layer implements the operation:\n",
      "    `outputs = activation(inputs.kernel + bias)`\n",
      "    Where `activation` is the activation function passed as the `activation`\n",
      "    argument (if not `None`), `kernel` is a weights matrix created by the layer,\n",
      "    and `bias` is a bias vector created by the layer\n",
      "    (only if `use_bias` is `True`).\n",
      "    \n",
      "    Note: if the `inputs` tensor has a rank greater than 2, then it is\n",
      "    flattened prior to the initial matrix multiply by `kernel`.\n",
      "    \n",
      "    Arguments:\n",
      "      inputs: Tensor input.\n",
      "      units: Integer or Long, dimensionality of the output space.\n",
      "      activation: Activation function (callable). Set it to None to maintain a\n",
      "        linear activation.\n",
      "      use_bias: Boolean, whether the layer uses a bias.\n",
      "      kernel_initializer: Initializer function for the weight matrix.\n",
      "      bias_initializer: Initializer function for the bias.\n",
      "      kernel_regularizer: Regularizer function for the weight matrix.\n",
      "      bias_regularizer: Regularizer function for the bias.\n",
      "      activity_regularizer: Regularizer function for the output.\n",
      "      trainable: Boolean, if `True` also add variables to the graph collection\n",
      "        `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).\n",
      "      name: String, the name of the layer.\n",
      "      reuse: Boolean, whether to reuse the weights of a previous layer\n",
      "        by the same name.\n",
      "    \n",
      "    Returns:\n",
      "      Output tensor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.layers.dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function conv2d_transpose in module tensorflow.python.ops.nn_ops:\n",
      "\n",
      "conv2d_transpose(value, filter, output_shape, strides, padding='SAME', data_format='NHWC', name=None)\n",
      "    The transpose of `conv2d`.\n",
      "    \n",
      "    This operation is sometimes called \"deconvolution\" after [Deconvolutional\n",
      "    Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf), but is\n",
      "    actually the transpose (gradient) of `conv2d` rather than an actual\n",
      "    deconvolution.\n",
      "    \n",
      "    Args:\n",
      "      value: A 4-D `Tensor` of type `float` and shape\n",
      "        `[batch, height, width, in_channels]` for `NHWC` data format or\n",
      "        `[batch, in_channels, height, width]` for `NCHW` data format.\n",
      "      filter: A 4-D `Tensor` with the same type as `value` and shape\n",
      "        `[height, width, output_channels, in_channels]`.  `filter`'s\n",
      "        `in_channels` dimension must match that of `value`.\n",
      "      output_shape: A 1-D `Tensor` representing the output shape of the\n",
      "        deconvolution op.\n",
      "      strides: A list of ints. The stride of the sliding window for each\n",
      "        dimension of the input tensor.\n",
      "      padding: A string, either `'VALID'` or `'SAME'`. The padding algorithm.\n",
      "        See the @{tf.nn.convolution$comment here}\n",
      "      data_format: A string. 'NHWC' and 'NCHW' are supported.\n",
      "      name: Optional name for the returned tensor.\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor` with the same type as `value`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If input/output depth does not match `filter`'s shape, or if\n",
      "        padding is other than `'VALID'` or `'SAME'`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.conv2d_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
